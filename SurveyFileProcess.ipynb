{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duke Qualtrics Survey Data File Processing Guide\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data File (Download from Duke Qualtrics Platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Mapping_Survey11_19.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1:\n",
    "\n",
    "Separate the Mapping Data and Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def phase1clean(df):\n",
    "    mapping_data = df.loc[:,'Q1':'Q6'].copy()\n",
    "    analyze_data = df.loc[:,'Q21':].copy()\n",
    "    mapping_data.dropna(axis = 0, how='all',inplace=True)\n",
    "       \n",
    "    return mapping_data, analyze_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping, analysis = phase1clean(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2:\n",
    "\n",
    "Merge survey answers in \"other\" sections of a question with other selected answers of that question\n",
    "Remove Mapping Data before a specific date (06/19/2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase2clean(df):\n",
    "    \n",
    "    def cleanOtro(row):\n",
    "        for index,item in row.items():\n",
    "            if isinstance(item, str):\n",
    "                if \"Otro\" in item:\n",
    "                    if not pd.isna(row[index]):\n",
    "                        list_ = row[index].split(',')\n",
    "                    list_.pop()\n",
    "                    if isinstance(row[row.index.get_loc(index)+1], str):\n",
    "                        list_.append(str.translate(row[row.index.get_loc(index)+1],str.maketrans(',','/')))\n",
    "                    row[index] = \",\".join(list_)\n",
    "                    row[row.index.get_loc(index)+1] = np.nan\n",
    "        return row\n",
    "    \n",
    "    df = df.apply(cleanOtro,axis=1)\n",
    "    df.drop('Q19_9_TEXT',inplace=True,axis=1)\n",
    "    df.drop('Q2_TEXT',inplace=True,axis=1)\n",
    "    df.drop(1, axis=0,inplace=True)\n",
    "    \n",
    "    # Remove data before the 61st row\n",
    "    df = df.loc[61:,:]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = phase2clean(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix the names of categories\n",
    "\n",
    "The Activity Category section of the survey is modified to be Javascript code for better display. Change the corresponding columns back to the name of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fix_categories(row):\n",
    "    \n",
    "    Categories = ['Primer Nivel de Atención','Educación para el Cambio de Comportamiento','Agua potable y saneamiento ambiental','Disponibilidad y Economía Familiar']\n",
    "    new_categories = []\n",
    "    if not pd.isna(row['Q27_1']):\n",
    "        new_categories.append(Categories[0])\n",
    "    if not pd.isna(row['Q27_30']):\n",
    "        new_categories.append(Categories[1])\n",
    "    if not pd.isna(row['Q27_31']):\n",
    "        new_categories.append(Categories[2])\n",
    "    if not pd.isna(row['Q27_32']):\n",
    "        new_categories.append(Categories[3])\n",
    "\n",
    "    return new_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group answer columns\n",
    "\n",
    "The data file provided by Duke Qualtrics records every answer in a separate column. This function is used to put answers of the same question into one group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByGroup(lst):\n",
    "    groups = []\n",
    "    for item in lst:\n",
    "        match = False\n",
    "        for g in range(len(groups)):\n",
    "            group = groups[g]\n",
    "            parent = group[0]\n",
    "            try:\n",
    "                if parent[:4] == item[:4]:\n",
    "                    \n",
    "                    if parent[-1] == ')':\n",
    "                        if 'TEXT' in item and 'TEXT' not in parent:\n",
    "                            pass\n",
    "                        else:\n",
    "                            if parent[-3:] == item[-3:]:\n",
    "                                group.append(item)\n",
    "                                match = True\n",
    "                    else:\n",
    "                        group.append(item)\n",
    "                        match = True\n",
    "            except:\n",
    "                pass\n",
    "        if not match:\n",
    "            groups.append([item])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String processing tools\n",
    "\n",
    "def make_string_list(series):\n",
    "    lst = []\n",
    "    if len(series) == 0:\n",
    "        return lst\n",
    "    \n",
    "    for i in range(len(series)):\n",
    "        lst.append(series[i])\n",
    "    return lst\n",
    "\n",
    "def make_string(series):\n",
    "    series = series.dropna()\n",
    "    lst = []\n",
    "    if len(series) == 0:\n",
    "        return 'unknown'\n",
    "    \n",
    "    for i in range(len(series)):\n",
    "\n",
    "        lst.append(str(series[i]))\n",
    "    \n",
    "    if len(lst) > 1:\n",
    "        return ','.join(lst)\n",
    "    else:\n",
    "        return lst[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 3:\n",
    "\n",
    "Apply various steps to each response in the mapping data file. Transform each response into multiple rows of different Municipios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def clean_row_new(row):\n",
    "    \n",
    "    \n",
    "    categories = fix_categories(row)\n",
    "    \n",
    "    firstpart = row[:5]\n",
    "    lastpart = row[-25:]\n",
    "    middlepart = row[5:-25]\n",
    "    middlepart = middlepart.drop(['Q27_1','Q27_30','Q27_31','Q27_32'])\n",
    "    middlepart = middlepart.dropna()\n",
    "   \n",
    "    row = firstpart.append(middlepart).append(lastpart)\n",
    "\n",
    "    Groups = sortByGroup(row.index.values)\n",
    "    \n",
    "    df = pd.DataFrame(columns = ['NameOrg','TypeOrg','NameProg','StartDate','EndDate',\n",
    "                        'Category','Activity','Area','Municipio',\n",
    "                        'Beneficiaries','NumBeneficiaries','EduIntervention(Y/N)','EduIntervention',\n",
    "                       'Place','Nutritionist','Goal'])\n",
    "    temp = pd.Series(index=['NameOrg','TypeOrg','NameProg','StartDate','EndDate',\n",
    "                        'Category','Activity','Area','Municipio',\n",
    "                        'Beneficiaries','NumBeneficiaries','EduIntervention(Y/N)','EduIntervention',\n",
    "                       'Place','Nutritionist','Goal'])\n",
    "\n",
    "    index = 4\n",
    "\n",
    "    num_categories = len(categories)\n",
    "    current_index = index+num_categories+1\n",
    "    for i in range(num_categories):\n",
    "        temp['Goal'] = make_string(row[Groups[-1]])\n",
    "        temp['Nutritionist'] =  make_string(row[Groups[-2]])\n",
    "        temp['Place'] =  make_string(row[Groups[-3]])\n",
    "        temp['EduIntervention'] =  make_string(row[Groups[-4]])\n",
    "        temp['EduIntervention(Y/N)'] =  make_string(row[Groups[-5]])\n",
    "        temp[:5] = row[:5]\n",
    "        temp['Category'] = categories[i]\n",
    "        \n",
    "        activities = make_string_list(row[Groups[index+i+1]])\n",
    "        num_activities = len(activities)\n",
    "    \n",
    "        for j in range(num_activities):\n",
    "            \n",
    "            temp['Activity'] = activities[j]\n",
    "            areas = make_string_list(row[Groups[current_index]])\n",
    "            num_areas = len(areas)\n",
    "            current_index += 1\n",
    "            \n",
    "            if current_index >= len(Groups):\n",
    "                return df\n",
    "            \n",
    "            beneficiaries = make_string_list(row[Groups[current_index]])\n",
    "\n",
    "            temp['Beneficiaries'] = make_string(row[Groups[current_index]])\n",
    "            num_beneficiaries = len(beneficiaries)\n",
    "            current_index += 1\n",
    "            \n",
    "            if current_index >= len(Groups):\n",
    "                return df           \n",
    "            \n",
    "            for k in range(num_areas):\n",
    "                temp[7] = areas[k]\n",
    "                if pd.isna(row[current_index]):\n",
    "                    return\n",
    "       \n",
    "                municipios = make_string_list(row[Groups[current_index]])\n",
    "                num_municipios = len(municipios)\n",
    "                current_index += 1\n",
    "                \n",
    "                if current_index >= len(Groups):\n",
    "                    return df\n",
    "                \n",
    "                for l in range(num_municipios):\n",
    "                   \n",
    "                    temp['Municipio'] = municipios[l]\n",
    "                    if 'TEXT' in Groups[current_index][0]:\n",
    "                        temp['NumBeneficiaries'] = make_string(row[Groups[current_index]])\n",
    "                        current_index += 1\n",
    "                    else:\n",
    "                        temp['NumBeneficiaries'] = 'unknown'\n",
    "                    \n",
    "                    df = df.append(temp,ignore_index=True)         \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns = ['NameOrg','TypeOrg','NameProg','StartDate','EndDate',\n",
    "                        'Category','Activity','Area','Municipio',\n",
    "                        'Beneficiaries','NumBeneficiaries','EduIntervention(Y/N)','EduIntervention',\n",
    "                       'Place','Nutritionist','Goal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing response 0..\n",
      "Processing response 1..\n",
      "Processing response 2..\n",
      "Processing response 3..\n",
      "Processing response 4..\n",
      "Processing response 5..\n",
      "Processing response 6..\n",
      "Processing response 7..\n",
      "Processing response 8..\n",
      "Processing response 9..\n",
      "Processing response 10..\n",
      "Processing response 11..\n",
      "Processing response 12..\n",
      "Processing response 13..\n",
      "Processing response 14..\n",
      "Processing response 15..\n",
      "Processing response 16..\n",
      "Processing response 17..\n",
      "Processing response 18..\n",
      "Processing response 19..\n",
      "Processing response 20..\n",
      "Processing response 21..\n",
      "Processing response 22..\n",
      "Processing response 23..\n",
      "Processing response 24..\n",
      "Processing response 25..\n",
      "Processing response 26..\n",
      "Processing response 27..\n",
      "Processing response 28..\n",
      "Processing response 29..\n",
      "Processing response 30..\n",
      "Processing response 31..\n",
      "Processing response 32..\n",
      "Processing response 33..\n",
      "Processing response 34..\n",
      "Processing response 35..\n",
      "Processing response 36..\n",
      "Processing response 37..\n",
      "Processing response 38..\n",
      "Processing response 39..\n",
      "Processing response 40..\n",
      "Processing response 41..\n",
      "Processing response 42..\n",
      "Processing response 43..\n",
      "Processing response 44..\n",
      "Processing response 45..\n",
      "Processing response 46..\n",
      "Processing response 47..\n",
      "Processing response 48..\n",
      "Processing response 49..\n",
      "Processing response 50..\n",
      "Processing response 51..\n",
      "Processing response 52..\n",
      "Processing response 53..\n",
      "Processing response 54..\n",
      "Processing response 55..\n",
      "Processing response 56..\n",
      "Processing response 57..\n",
      "Processing response 58..\n",
      "Processing response 59..\n",
      "Processing response 60..\n",
      "Processing response 61..\n",
      "Processing response 62..\n",
      "Processing response 63..\n",
      "Processing response 64..\n",
      "Processing response 65..\n",
      "Processing response 66..\n",
      "Processing response 67..\n",
      "Processing response 68..\n",
      "Processing response 69..\n",
      "Processing response 70..\n",
      "Processing response 71..\n",
      "Processing response 72..\n",
      "Processing response 73..\n",
      "Processing response 74..\n",
      "Processing response 75..\n",
      "Processing response 76..\n",
      "Processing response 77..\n",
      "Processing response 78..\n",
      "Processing response 79..\n",
      "Processing response 80..\n",
      "Processing response 81..\n",
      "Processing response 82..\n",
      "Processing response 83..\n",
      "Processing response 84..\n",
      "Processing response 85..\n",
      "Processing response 86..\n",
      "Processing response 87..\n",
      "Processing response 88..\n",
      "Processing response 89..\n",
      "Processing response 90..\n",
      "Processing response 91..\n",
      "Processing response 92..\n",
      "Processing response 93..\n",
      "Processing response 94..\n",
      "Processing response 95..\n",
      "Processing response 96..\n",
      "Processing response 97..\n",
      "Processing response 98..\n",
      "Processing response 99..\n",
      "Processing response 100..\n",
      "Processing response 101..\n",
      "Processing response 102..\n",
      "Processing response 103..\n",
      "Processing response 104..\n",
      "Processing response 105..\n",
      "Processing response 106..\n",
      "Processing response 107..\n",
      "Processing response 108..\n",
      "Processing response 109..\n",
      "Processing response 110..\n",
      "Processing response 111..\n",
      "Processing response 112..\n",
      "Processing response 113..\n",
      "Processing response 114..\n",
      "Processing response 115..\n",
      "Processing response 116..\n",
      "Processing response 117..\n",
      "Processing response 118..\n",
      "Processing response 119..\n",
      "Processing response 120..\n",
      "Processing response 121..\n",
      "Processing response 122..\n",
      "Processing response 123..\n",
      "Processing response 124..\n",
      "Processing response 125..\n",
      "Processing response 126..\n",
      "Processing response 127..\n",
      "Processing response 128..\n",
      "Processing response 129..\n",
      "Processing response 130..\n",
      "Processing response 131..\n",
      "Processing response 132..\n",
      "Processing response 133..\n",
      "Processing response 134..\n",
      "Processing response 135..\n",
      "Processing response 136..\n",
      "Processing response 137..\n",
      "Processing response 138..\n",
      "Processing response 139..\n",
      "Processing response 140..\n",
      "Processing response 141..\n",
      "Processing response 142..\n",
      "Processing response 143..\n",
      "Processing response 144..\n",
      "Processing response 145..\n",
      "Processing response 146..\n",
      "Processing response 147..\n",
      "Processing response 148..\n",
      "Processing response 149..\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(mapping)):\n",
    "    print(\"Processing response {}..\".format(i))\n",
    "    new_df = clean_row_new(mapping.iloc[i,:])\n",
    "    result = result.append(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Geocodes to the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocodes = pd.read_csv(\"geocodes.csv\")\n",
    "result = result.merge(geocodes.drop('Country',axis=1),how = 'left',on=['Area','Municipio'],left_index=True)\n",
    "cols = result.columns.tolist()\n",
    "cols.insert(9,cols[-1])\n",
    "cols.pop()\n",
    "cols.insert(9,cols[-1])\n",
    "cols.pop()\n",
    "result = result[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add respond date to the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.DataFrame(data=[df['StartDate'],df['EndDate'],df['Q1']]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data.rename({'Q1':'NameOrg','StartDate':'RespondStart','EndDate':'RespondEnd'},axis=1)\n",
    "Data = Data.dropna()\n",
    "Data = Data.reset_index(drop=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Data.merge(result,on='NameOrg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview of the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output file into a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"mapping_file_11_19.csv\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_text(row):\n",
    "    new_series = pd.Series()\n",
    "    groups = sortByGroup(row.index.values)\n",
    "    for group in groups:\n",
    "        lst = []\n",
    "        for item in row[group]:\n",
    "            if not pd.isna(item):\n",
    "                lst.append(str(item))\n",
    "        new_series[group[0][:4]] = ','.join(lst)\n",
    "    return new_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = pd.concat([pd.DataFrame(mapping.iloc[:,:5]),pd.DataFrame(analysis)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_analysis(analysis):\n",
    "    new_df = pd.DataFrame()\n",
    "    df = pd.concat([pd.DataFrame(mapping.iloc[:,:5]),pd.DataFrame(analysis.iloc[:,:-3])],axis=1)\n",
    "    for i in range(len(df)):\n",
    "        new_series = join_text(df.iloc[i,:])\n",
    "        new_df= new_df.append(new_series,ignore_index=True)\n",
    "    new_df =new_df[new_series.index.values]\n",
    "    return new_df\n",
    "\n",
    "analysis_file = clean_analysis(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview of the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analysis_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output file into a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_file.dropna(how='all',axis=0)\n",
    "analysis_file.to_csv(\"Analysis_11_19.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
